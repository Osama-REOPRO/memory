- [ ] Make small change to design, make the access hierarchical but with the optimization talked about in the video
	- So you only access the cache initially, only access main memory in case of miss, when you do miss, the return could be simultaneous to both cache and output
- [[(decision)]] the state output of a lower cache is input to the cache above it
	- so each cache has information of the cache directly below it
	- so it knows if lower cache has missed and kicks into action
- [[(decision)]] a [[read operation]] will function in the fashion shown [[read operation procedure|here]]
- [[(observation)]] the only information that needs to be communicated by caches to the outside world is the following
	- cache miss to upper cache: so the upper cache starts looking
	- cache hit to all lower caches and to output: so lower caches write the new data and so output becomes valid
	- cache valid 
- when hit, no need to tell upper cache, simply leave it alone, it shouldn't do anything
~~- [[(observation)]] lower caches when they miss, what they see is the upper cache is [[valid state]] for a while (which means it is searching from the moment [[hit state]] entered by lower cache), then it should turn into [[hit state]] or [[miss state]], if turned into [[hit state]], then this lower cache should prepare to latch data when upper cache turns back into [[valid state]]
	- so for a cache to latch data the upper state being in [[valid state]] isn't enough, the upper cache needs to first enter [[hit state]], then~~
- so a [[miss state]] is communicated sequentially to upper caches, while a hit is communicated in parallel to all lower caches
	- a miss climbs up, cache by cache, one at a time
	- then we get a hit, and it is communicated in parallel to all lower caches at the same time and to the output