- [[(decision)]] no need to turn the register arrays (tags, valid bits, dirty bits, data fields, etc.) into a single register array
	- that will simply complicated things and add nothing
	- physically these fields might occupy adjacent memory locations, but they don't need to be in a single reg array in code, that is unnecessary
	- keeping them separate but with compatible addressing actually makes everything simpler
	- these arrays are simply representations, they aren't the physical thing
- [x] get N where hit happened
- [ ] lookup how memory capacity correlates with latency, then implement memory delay based on the capacity parameter
- [[(decision)]] [[cache]] itself is responsible for fetching data when it misses
	- so that we can string together as many as we want
	- as opposed to an external module detecting the miss and fetching the data somewhere else and writing it to the cache that missed, that would require adding logic each time a new cache level is added
	- this way we can simply chain caches together and each will ask the next when it misses
	- potential [[(downside)]] does this mean that we miss out on parallel reading of all caches? (No)
- [[(decision)]] parallel operation of chained [[cache]]s should proceed like this:
	- read/write (memory operation) order given to all cache levels at simultaneously
	- we wait for a hit signal from one of the caches
	- when hit detected, that cache that hit writes data simultaneously to output and to all lower caches who missed
	- when a cache misses it should get ready to receive data from an upper level cache
	- entire memory block is busy until missed caches are written with missed value
	- [[(implication)]] data read out of memory block potentially before being written to lowest cache
	- [[(implementation)]] all will be connected to the signal of the data that hit, when hit happens all who missed get written simultaneously
		- as you can see here ([[cache simultaneous operation]])
- [[(decision)]] read procedure
	1. lookup state
		- cache searches internally for data
		- simultaneously, cache anticipates an earlier hit from another faster cache
		- if found internally first, go to read_hit state
		- if found externally first, simply terminate operation, go back to idle_state
			- because this means that a faster lower cache downstream found it first, in that case this larger higher slower cache doesn't need to do anything
	2. read_hit state
		- assert hit
		- assert read_data output
		- go to idle state
	3. idle state
		- deassert hit
		- hold output asserted
- [[(assumption]] if lower cache has a piece of data, then necessarily all caches upstream must also hold that piece
	- isn't that wasteful? (maybe not)
- [[(decision)]] lowest cache will eventually be held at hit state and will hold and output the read data
	- so even if it misses initially, another cache which did hit will be outputting to the world, it reads that output and once it gets it it takes over and the larger cache lets go
	- so eventually the smallest cache takes over
- [[(decision)]] externally the memory will have the following states:
	- uninitialized
		- before it is read from or written to first, the output is meaningless
		- on [[i_mem_operation]], read all inputs necessary for the next operation (like [[i_address]] and [[i_write_data]] etc.) into internal registers, go to busy state
	- busy
		- memory request received, processing, output meaningless, not responsive to inputs except reset
		- ends when we get a hit, go to [[valid state]]
	- valid
		- request externally fulfilled, output meaningful, can't accept new requests, internally busy
		- so externally done but internally busy
	- ready
		- internally idle, output meaningful, can accept new requests
- [ ] if received address is already being output, do nothing
- [[(decision)]] [[i_mem_operation]] must be held asserted along with [[i_address]] and [[i_write_data]] as long as memory is in [[uninitialized state]] or [[ready state]] until memory enters [[busy state]], then [[i_address]] may be changed for next operation or [[i_mem_operation]] may be deasserted if this is the last operation
- [[(decision)]] when memory in [[busy state]] or [[valid state]], all necessary inputs are stored internally, external changes other than reset have no effect